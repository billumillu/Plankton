{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c998ff-2a85-4743-82be-b7dac8b7389e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eba661-86ab-48eb-bc34-e727a2ad759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install Augmentor scikit-learn gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe228c62-a957-48b9-a5fc-0adf51610f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import GPUtil\n",
    "import random\n",
    "import shutil\n",
    "import Augmentor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small, MobileNetV3Large, VGG16, InceptionV3, ResNet50, ResNet101, ResNet152\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_input_mobilenet_v2\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as preprocess_input_mobilenet_v3\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_inceptionv3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as preprocess_input_resnet101\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_input_resnet152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99778eb-cd7b-492f-a1b9-da2f7416bae1",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859f305-61b7-43c9-add0-b0e0ed207d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9f9d3-7c25-4b3d-88fa-95e82910fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GPU information\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU {gpu.id}: {gpu.name}, GPU Load: {gpu.load * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d823e6",
   "metadata": {},
   "source": [
    "### 6:2:2 split of each folder -> create csv files -> check for duplicates -> check for leakage -> remove duplicates and leakage (if any) -> oversample train to 3000 using augmentations -> creating final csv files [all done only once, hence, commented.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36215fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "### Split by 6:2:2, creating separate train, val and test folders\n",
    "\n",
    "def split_data(input_folder, output_folder):\n",
    "    # Create train, val, and test folders\n",
    "    train_folder = os.path.join(output_folder, 'train')\n",
    "    val_folder = os.path.join(output_folder, 'val')\n",
    "    test_folder = os.path.join(output_folder, 'test')\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Dictionary to store counts for each class\n",
    "    class_counts = {}\n",
    "\n",
    "    # Iterate through each class folder in the input folder\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        class_path = os.path.join(input_folder, class_folder)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Create subfolders in train, val, and test\n",
    "        train_class_folder = os.path.join(train_folder, class_folder)\n",
    "        val_class_folder = os.path.join(val_folder, class_folder)\n",
    "        test_class_folder = os.path.join(test_folder, class_folder)\n",
    "\n",
    "        os.makedirs(train_class_folder, exist_ok=True)\n",
    "        os.makedirs(val_class_folder, exist_ok=True)\n",
    "        os.makedirs(test_class_folder, exist_ok=True)\n",
    "\n",
    "        # Get the list of images in the class folder\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Calculate the number of images for each split\n",
    "        total_images = len(images)\n",
    "        train_split = int(0.6 * total_images)\n",
    "        val_split = int(0.2 * total_images)\n",
    "\n",
    "        # Copy images to train, val, and test folders\n",
    "        for i, image in enumerate(images):\n",
    "            src_path = os.path.join(class_path, image)\n",
    "            \n",
    "            if i < train_split:\n",
    "                dst_path = os.path.join(train_class_folder, image)\n",
    "            elif i < train_split + val_split:\n",
    "                dst_path = os.path.join(val_class_folder, image)\n",
    "            else:\n",
    "                dst_path = os.path.join(test_class_folder, image)\n",
    "\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "        # Update class counts dictionary\n",
    "        class_counts[class_folder] = {\n",
    "            'total': total_images,\n",
    "            'train': train_split,\n",
    "            'val': val_split,\n",
    "            'test': total_images - train_split - val_split\n",
    "        }\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Create csv for a folder\n",
    "\n",
    "def create_csv(input_folder, output_csv):\n",
    "    # Open CSV file in write mode\n",
    "    with open(output_csv, 'w', newline='') as csv_file:\n",
    "        # Create CSV writer\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write header\n",
    "        csv_writer.writerow(['Image_Path', 'Label'])\n",
    "\n",
    "        # Initialize count\n",
    "        total_rows = 0\n",
    "\n",
    "        # Iterate through each class folder in the input folder\n",
    "        for label in os.listdir(input_folder):\n",
    "            class_folder = os.path.join(input_folder, label)\n",
    "\n",
    "            # Skip if it's not a directory\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "\n",
    "            # Iterate through each image in the class folder\n",
    "            for image in os.listdir(class_folder):\n",
    "                # Get the image path\n",
    "                image_path = os.path.join(class_folder, image)\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                csv_writer.writerow([image_path, label])\n",
    "\n",
    "                # Increment the count\n",
    "                total_rows += 1\n",
    "\n",
    "    return total_rows\n",
    "\n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Oversample to n using augmentations\n",
    "\n",
    "def oversample_aug(main_folder, output_folder, n=3000):\n",
    "    # Iterate over subfolders\n",
    "    for subfolder in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Check if the directory contains images\n",
    "            if any(f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif')) for f in os.listdir(subfolder_path)):\n",
    "                # Create an Augmentor pipeline for each subfolder\n",
    "                pipeline = Augmentor.Pipeline(subfolder_path, output_directory=os.path.join(output_folder, subfolder))\n",
    "                # Add your augmentations here\n",
    "                pipeline.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\n",
    "                pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "                pipeline.flip_left_right(probability=0.5)\n",
    "                pipeline.flip_top_bottom(probability=0.5)\n",
    "\n",
    "                # Execute the augmentation process\n",
    "                pipeline.sample(n)  # Adjust the number of samples as needed\n",
    "            else:\n",
    "                print(f\"No images found in {subfolder_path}. Skipping.\")\n",
    "            \n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Check for dupliates in a csv file, on the column Image_Path\n",
    "            \n",
    "def check_duplicates(file):\n",
    "    df = pd.read_csv(f'/uoa/home/s04bs3/data/dasa/{file}.csv')\n",
    "    duplicates_specific_column= df[df.duplicated(subset=['Image_Path'])]\n",
    "    print(f\"\\nDuplicates in {file} based on Image_Path:\")\n",
    "    print(duplicates_specific_column)\n",
    "    \n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Functions to deal with leakage\n",
    "\n",
    "def extract_pattern(path):\n",
    "    pattern = r'(\\d{2}-\\d{2}-\\d{4}-\\d{2}-\\d{2}-\\d{2}\\.hvdfrm\\d+\\(\\d+,\\d+\\)-Z\\d+\\.\\d+)'\n",
    "    match = re.search(pattern, path)\n",
    "    return match.group() if match else None\n",
    "\n",
    "def get_paths_with_pattern(df):\n",
    "    return set(df['Image_Path'].apply(extract_pattern))\n",
    "\n",
    "def get_full_path(pattern, df):\n",
    "    # Find the row where Image_Path contains the pattern\n",
    "    match_row = df[df['Image_Path'].apply(lambda x: pattern in x)]\n",
    "    \n",
    "    # Assuming there is only one match, get the full path\n",
    "    full_path = match_row['Image_Path'].iloc[0] if not match_row.empty else None\n",
    "    \n",
    "    return full_path\n",
    "\n",
    "def check_leakage(train_path, val_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_paths = get_paths_with_pattern(train_df)\n",
    "    val_paths = get_paths_with_pattern(val_df)\n",
    "    test_paths = get_paths_with_pattern(test_df)\n",
    "\n",
    "    overlap_train_val = train_paths.intersection(val_paths)\n",
    "    overlap_train_test = train_paths.intersection(test_paths)\n",
    "    overlap_val_test = val_paths.intersection(test_paths)\n",
    "\n",
    "    print(\"Overlap between train and val:\", overlap_train_val)\n",
    "    print(\"Overlap between train and test:\", overlap_train_test)\n",
    "    print(\"Overlap between val and test:\", overlap_val_test)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test\n",
    "\n",
    "def remove_leakage(train_df, val_df, overlap_train_val, overlap_train_test):\n",
    "    # Filter rows from train_df where Image_Path is in overlap_train_val or overlap_train_test\n",
    "    train_df_no_overlap = train_df[~train_df['Image_Path'].apply(extract_pattern).isin(overlap_train_val.union(overlap_train_test))]\n",
    "\n",
    "    # Filter rows from val_df where Image_Path is in overlap_train_val\n",
    "    val_df_no_overlap = val_df[~val_df['Image_Path'].apply(extract_pattern).isin(overlap_train_val)]\n",
    "\n",
    "    return train_df_no_overlap, val_df_no_overlap\n",
    "\n",
    "def delete_images(image_paths):\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "            print(f\"Deleted: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {path}: {e}\")\n",
    "            \n",
    "            import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 6:2:2 split\n",
    "\n",
    "# # Provide the input and output folder paths\n",
    "# input_folder_path = \"/uoa/home/s04bs3/data/dasa/ALL/\"\n",
    "# output_folder_path = \"/uoa/home/s04bs3/data/dasa/\"\n",
    "\n",
    "# counts = split_data(input_folder_path, output_folder_path)\n",
    "\n",
    "# # Display counts for each class\n",
    "# for class_name, count_info in counts.items():\n",
    "#     print(f\"Class: {class_name}\")\n",
    "#     print(f\"Total: {count_info['total']} | Train: {count_info['train']} | Val: {count_info['val']} | Test: {count_info['test']}\")\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276bcb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# import shutil\n",
    "\n",
    "# def convert_folder_to_rgb(input_folder, output_folder):\n",
    "#     # Create output folder if it doesn't exist\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "\n",
    "#     # Initialize counts for LA and RGB images\n",
    "#     la_count = 0\n",
    "#     rgb_count = 0\n",
    "\n",
    "#     # Iterate through each folder in the input directory\n",
    "#     for folder_name in os.listdir(input_folder):\n",
    "#         folder_path = os.path.join(input_folder, folder_name)\n",
    "#         output_folder_path = os.path.join(output_folder, folder_name)\n",
    "\n",
    "#         # Create output folder for this folder if it doesn't exist\n",
    "#         if not os.path.exists(output_folder_path):\n",
    "#             os.makedirs(output_folder_path)\n",
    "\n",
    "#         # Iterate through each image file in the folder\n",
    "#         for image_name in os.listdir(folder_path):\n",
    "#             image_path = os.path.join(folder_path, image_name)\n",
    "#             output_image_path = os.path.join(output_folder_path, image_name)\n",
    "\n",
    "#             # Check if the image is a PNG or BMP file\n",
    "#             if image_name.lower().endswith(('.png', '.bmp')):\n",
    "#                 # Check if the image is in LA format\n",
    "#                 if is_la_image(image_path):\n",
    "#                     # Convert LA image to RGB and save it in the output folder\n",
    "#                     la_to_rgb(image_path, output_image_path)\n",
    "#                     la_count += 1\n",
    "#                 else:\n",
    "#                     # If the image is already in RGB format, copy it to the output folder\n",
    "#                     shutil.copy(image_path, output_image_path)\n",
    "#                     rgb_count += 1\n",
    "\n",
    "#     print(f\"LA images found: {la_count}\")\n",
    "#     print(f\"RGB images found: {rgb_count}\")\n",
    "\n",
    "# def is_la_image(image_path):\n",
    "#     # Check if the image has an alpha channel (indicating LA format)\n",
    "#     with Image.open(image_path) as img:\n",
    "#         return img.mode == \"LA\"\n",
    "\n",
    "# def la_to_rgb(input_path, output_path):\n",
    "#     with Image.open(input_path) as img:\n",
    "#         # Convert LA image to RGB\n",
    "#         img_rgb = img.convert(\"RGB\")\n",
    "#         # Save the converted image\n",
    "#         img_rgb.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_folder = \"/uoa/home/s04bs3/data/dasa/train/\"\n",
    "# output_folder = \"/uoa/home/s04bs3/data/dasa/train_RGB/\"\n",
    "\n",
    "# convert_folder_to_rgb(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### create csv -- train.csv, val.csv, test.csv & check for duplicates\n",
    "\n",
    "# for n in ['train_RGB', 'val_RGB', 'test_RGB']:\n",
    "#     input_folder_path = f\"/uoa/home/s04bs3/data/dasa/{n}/\"\n",
    "#     output_csv_path = f\"/uoa/home/s04bs3/data/dasa/{n}.csv\"\n",
    "#     total_rows = create_csv(input_folder_path, output_csv_path)\n",
    "#     print(f'\\nTotal rows created: {total_rows}')\n",
    "#     check_duplicates(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage:\n",
    "# train_path = '/uoa/home/s04bs3/data/dasa/train_RGB.csv'\n",
    "# val_path = '/uoa/home/s04bs3/data/dasa/val_RGB.csv'\n",
    "# test_path = '/uoa/home/s04bs3/data/dasa/test_RGB.csv'\n",
    "\n",
    "# train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test = check_leakage(train_path, val_path, test_path)\n",
    "# train_df_no_overlap, val_df_no_overlap = remove_leakage(train_df, val_df, overlap_train_val, overlap_train_test)\n",
    "\n",
    "# # Get full paths for overlapping images\n",
    "# full_paths_train = [get_full_path(pattern, train_df) for pattern in overlap_train_val.union(overlap_train_test) if pattern is not None]\n",
    "# full_paths_val = [get_full_path(pattern, val_df) for pattern in overlap_val_test if pattern is not None]\n",
    "\n",
    "\n",
    "# # Delete images\n",
    "# delete_images(full_paths_train)\n",
    "# delete_images(full_paths_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### oversample using augmentations to n=3000\n",
    "\n",
    "# main_folder = \"/uoa/home/s04bs3/data/dasa/train_RGB\"\n",
    "# output_folder = \"/uoa/home/s04bs3/data/dasa/train_o_RGB/\"\n",
    "\n",
    "# oversample_aug(main_folder, output_folder, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b2a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### final csv files\n",
    "\n",
    "# for n in ['train_o_RGB','val_RGB','test_RGB']:\n",
    "#     input_folder_path = f\"/uoa/home/s04bs3/data/dasa/{n}/\"\n",
    "#     output_csv_path = f\"/uoa/home/s04bs3/data/dasa/{n}.csv\"\n",
    "#     total_rows = create_csv(input_folder_path, output_csv_path)\n",
    "#     print(f'Total rows created: {total_rows}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62196693-faef-40a7-b3cb-44ba8899f61c",
   "metadata": {},
   "source": [
    "### Functions to train, evaluate and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7363895-29ad-4ae0-9f3b-ebf8327e295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_data, val_data, epochs=10, batch_size=32):\n",
    "    \n",
    "    target_size=(224,224)\n",
    "\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size=(299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    \n",
    "    # Set up data generators\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "\n",
    "    # Set up data generators\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Build model based on model_name\n",
    "    base_model = None\n",
    "\n",
    "    if model_name == \"MobileNetV2\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV2-0.75\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV2-0.5\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.5)\n",
    "    elif model_name == \"MobileNetV3Small\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Small-0.75\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Small-Min\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"MobileNetV3Large\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Large-0.75\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Large-Min\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"InceptionV3\":\n",
    "        base_model = InceptionV3(input_shape=(299,299, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet101\":\n",
    "        base_model = ResNet101(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet152\":\n",
    "        base_model = ResNet152(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    if base_model:\n",
    "        base_model.trainable = False\n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(12, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Define callbacks (EarlyStopping)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(f\"/uoa/home/s04bs3/data/dasa/models_RGB/{model_name}.h5\", save_best_only=True)\n",
    "\n",
    "        # Start the timer for training\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        # Stop the timer for training\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate and print the training time\n",
    "        training_time = round(end_time - start_time,2)\n",
    "        print(f\"Training Time: {training_time} seconds\")\n",
    "\n",
    "        return model, history\n",
    "\n",
    "    else:\n",
    "        print(f\"Model {model_name} not recognized.\")\n",
    "        return None, None\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def evaluate_model(model_name, model_path, test_csv_path, target_size=(224, 224), batch_size=32):\n",
    "    # Load the test data\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create an ImageDataGenerator for test data\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size = (299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)  # You may need to adjust this based on your training data preprocessing\n",
    "\n",
    "    # Configure the test generator\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False  # Important: set shuffle to False for reproducibility\n",
    "    )\n",
    "\n",
    "    # Start the timer for testing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    # Stop the timer for testing\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the testing time\n",
    "    testing_time = round(end_time - start_time, 2)\n",
    "    print(f\"Testing Time: {testing_time} seconds\")\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Convert true labels to class labels\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred_classes)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    # Calculate and print classification report\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    save_results(model_name, conf_mat, report, testing_time)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def save_results(model_name, conf_mat, report, testing_time):\n",
    "    # Save all results in a single text file\n",
    "    with open(f\"/uoa/home/s04bs3/data/dasa/results_RGB/{model_name}_results.txt\", 'w') as file:\n",
    "        file.write(\"Confusion Matrix:\\n\")\n",
    "        file.write(np.array_str(conf_mat))\n",
    "        file.write(\"\\n\\nClassification Report:\\n\")\n",
    "        file.write(report)\n",
    "        file.write(f\"\\nTesting Time: {testing_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d9cdd-7262-42de-85f5-6f0b6508718a",
   "metadata": {},
   "source": [
    "### Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f40a3d-a926-49b3-93ac-c46ba8189f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = [\"MobileNetV2\",\"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "train_data = pd.read_csv(\"/uoa/home/s04bs3/data/dasa/train_o_RGB.csv\")\n",
    "val_data = pd.read_csv(\"/uoa/home/s04bs3/data/dasa/val_RGB.csv\")\n",
    "test_csv_path = '/uoa/home/s04bs3/data/dasa/test_RGB.csv'\n",
    "\n",
    "for n in range(len(model_name)):\n",
    "    # Train the model\n",
    "    model, history = train_model(model_name[n], train_data, val_data, epochs=30, batch_size=64)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model_path = f'/uoa/home/s04bs3/data/dasa/models_RGB/{model_name[n]}.h5'    \n",
    "    evaluate_model(model_name[n], model_path, test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2fde0-0612-473d-9c0b-08e473e6b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to your saved models directory\n",
    "models_directory = '/uoa/home/s04bs3/data/dasa/models/'\n",
    "\n",
    "# List of model names\n",
    "model_name = [\"MobileNetV2\", \"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "for model in model_name:\n",
    "    # Load the model\n",
    "    model_path = os.path.join(models_directory, f'{model}.h5')\n",
    "    loaded_model = load_model(model_path)\n",
    "\n",
    "    # Get the size of the model file\n",
    "    model_size_bytes = os.path.getsize(model_path)\n",
    "\n",
    "    # Convert size to MB\n",
    "    model_size_MB = model_size_bytes / (1024 * 1024)\n",
    "\n",
    "    # Get the number of parameters (in millions)\n",
    "    num_params = loaded_model.count_params() / 1e6\n",
    "\n",
    "    print(f\"{model} - Model Size: {model_size_MB:.2f} MB | Number of Parameters: {num_params:.2f} million\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16235521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
