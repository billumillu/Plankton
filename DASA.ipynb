{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c998ff-2a85-4743-82be-b7dac8b7389e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eba661-86ab-48eb-bc34-e727a2ad759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install Augmentor scikit-learn gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe228c62-a957-48b9-a5fc-0adf51610f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import GPUtil\n",
    "import random\n",
    "import shutil\n",
    "import Augmentor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small, MobileNetV3Large, VGG16, InceptionV3, ResNet50, ResNet101, ResNet152\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_input_mobilenet_v2\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as preprocess_input_mobilenet_v3\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_inceptionv3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as preprocess_input_resnet101\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_input_resnet152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99778eb-cd7b-492f-a1b9-da2f7416bae1",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0859f305-61b7-43c9-add0-b0e0ed207d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb9f9d3-7c25-4b3d-88fa-95e82910fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 Ti, GPU Load: 0.0%\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti, GPU Load: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Get GPU information\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU {gpu.id}: {gpu.name}, GPU Load: {gpu.load * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d823e6",
   "metadata": {},
   "source": [
    "### 6:2:2 split of each folder -> create csv files -> check for duplicates -> check for leakage -> remove duplicates and leakage (if any) -> oversample train to 3000 using augmentations -> creating final csv files [all done only once, hence, commented.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36215fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "### Split by 6:2:2, creating separate train, val and test folders\n",
    "\n",
    "def split_data(input_folder, output_folder):\n",
    "    # Create train, val, and test folders\n",
    "    train_folder = os.path.join(output_folder, 'train')\n",
    "    val_folder = os.path.join(output_folder, 'val')\n",
    "    test_folder = os.path.join(output_folder, 'test')\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Dictionary to store counts for each class\n",
    "    class_counts = {}\n",
    "\n",
    "    # Iterate through each class folder in the input folder\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        class_path = os.path.join(input_folder, class_folder)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Create subfolders in train, val, and test\n",
    "        train_class_folder = os.path.join(train_folder, class_folder)\n",
    "        val_class_folder = os.path.join(val_folder, class_folder)\n",
    "        test_class_folder = os.path.join(test_folder, class_folder)\n",
    "\n",
    "        os.makedirs(train_class_folder, exist_ok=True)\n",
    "        os.makedirs(val_class_folder, exist_ok=True)\n",
    "        os.makedirs(test_class_folder, exist_ok=True)\n",
    "\n",
    "        # Get the list of images in the class folder\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Calculate the number of images for each split\n",
    "        total_images = len(images)\n",
    "        train_split = int(0.6 * total_images)\n",
    "        val_split = int(0.2 * total_images)\n",
    "\n",
    "        # Copy images to train, val, and test folders\n",
    "        for i, image in enumerate(images):\n",
    "            src_path = os.path.join(class_path, image)\n",
    "            \n",
    "            if i < train_split:\n",
    "                dst_path = os.path.join(train_class_folder, image)\n",
    "            elif i < train_split + val_split:\n",
    "                dst_path = os.path.join(val_class_folder, image)\n",
    "            else:\n",
    "                dst_path = os.path.join(test_class_folder, image)\n",
    "\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "        # Update class counts dictionary\n",
    "        class_counts[class_folder] = {\n",
    "            'total': total_images,\n",
    "            'train': train_split,\n",
    "            'val': val_split,\n",
    "            'test': total_images - train_split - val_split\n",
    "        }\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Create csv for a folder\n",
    "\n",
    "def create_csv(input_folder, output_csv):\n",
    "    # Open CSV file in write mode\n",
    "    with open(output_csv, 'w', newline='') as csv_file:\n",
    "        # Create CSV writer\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write header\n",
    "        csv_writer.writerow(['Image_Path', 'Label'])\n",
    "\n",
    "        # Initialize count\n",
    "        total_rows = 0\n",
    "\n",
    "        # Iterate through each class folder in the input folder\n",
    "        for label in os.listdir(input_folder):\n",
    "            class_folder = os.path.join(input_folder, label)\n",
    "\n",
    "            # Skip if it's not a directory\n",
    "            if not os.path.isdir(class_folder):\n",
    "                continue\n",
    "\n",
    "            # Iterate through each image in the class folder\n",
    "            for image in os.listdir(class_folder):\n",
    "                # Get the image path\n",
    "                image_path = os.path.join(class_folder, image)\n",
    "\n",
    "                # Write the row to the CSV file\n",
    "                csv_writer.writerow([image_path, label])\n",
    "\n",
    "                # Increment the count\n",
    "                total_rows += 1\n",
    "\n",
    "    return total_rows\n",
    "\n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Oversample to n using augmentations\n",
    "\n",
    "def oversample_aug(main_folder, output_folder, n=3000):\n",
    "    # Iterate over subfolders\n",
    "    for subfolder in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            # Check if the directory contains images\n",
    "            if any(f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif')) for f in os.listdir(subfolder_path)):\n",
    "                # Create an Augmentor pipeline for each subfolder\n",
    "                pipeline = Augmentor.Pipeline(subfolder_path, output_directory=os.path.join(output_folder, subfolder))\n",
    "                # Add your augmentations here\n",
    "                pipeline.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\n",
    "                pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "                pipeline.flip_left_right(probability=0.5)\n",
    "                pipeline.flip_top_bottom(probability=0.5)\n",
    "\n",
    "                # Execute the augmentation process\n",
    "                pipeline.sample(n)  # Adjust the number of samples as needed\n",
    "            else:\n",
    "                print(f\"No images found in {subfolder_path}. Skipping.\")\n",
    "            \n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Check for dupliates in a csv file, on the column Image_Path\n",
    "            \n",
    "def check_duplicates(file):\n",
    "    df = pd.read_csv(f'/uoa/home/s04bs3/data/full/dasa/{file}.csv')\n",
    "    duplicates_specific_column= df[df.duplicated(subset=['Image_Path'])]\n",
    "    print(f\"\\nDuplicates in {file} based on Image_Path:\")\n",
    "    print(duplicates_specific_column)\n",
    "    \n",
    "### -------------------------------------------------------------------------\n",
    "\n",
    "### Functions to deal with leakage\n",
    "\n",
    "def extract_pattern(path):\n",
    "    pattern = r'(\\d{2}-\\d{2}-\\d{4}-\\d{2}-\\d{2}-\\d{2}\\.hvdfrm\\d+\\(\\d+,\\d+\\)-Z\\d+\\.\\d+)'\n",
    "    match = re.search(pattern, path)\n",
    "    return match.group() if match else None\n",
    "\n",
    "def get_paths_with_pattern(df):\n",
    "    return set(df['Image_Path'].apply(extract_pattern))\n",
    "\n",
    "def get_full_path(pattern, df):\n",
    "    # Find the row where Image_Path contains the pattern\n",
    "    match_row = df[df['Image_Path'].apply(lambda x: pattern in x)]\n",
    "    \n",
    "    # Assuming there is only one match, get the full path\n",
    "    full_path = match_row['Image_Path'].iloc[0] if not match_row.empty else None\n",
    "    \n",
    "    return full_path\n",
    "\n",
    "def check_leakage(train_path, val_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_paths = get_paths_with_pattern(train_df)\n",
    "    val_paths = get_paths_with_pattern(val_df)\n",
    "    test_paths = get_paths_with_pattern(test_df)\n",
    "\n",
    "    overlap_train_val = train_paths.intersection(val_paths)\n",
    "    overlap_train_test = train_paths.intersection(test_paths)\n",
    "    overlap_val_test = val_paths.intersection(test_paths)\n",
    "\n",
    "    print(\"Overlap between train and val:\", overlap_train_val)\n",
    "    print(\"Overlap between train and test:\", overlap_train_test)\n",
    "    print(\"Overlap between val and test:\", overlap_val_test)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test\n",
    "\n",
    "def remove_leakage(train_df, val_df, overlap_train_val, overlap_train_test):\n",
    "    # Filter rows from train_df where Image_Path is in overlap_train_val or overlap_train_test\n",
    "    train_df_no_overlap = train_df[~train_df['Image_Path'].apply(extract_pattern).isin(overlap_train_val.union(overlap_train_test))]\n",
    "\n",
    "    # Filter rows from val_df where Image_Path is in overlap_train_val\n",
    "    val_df_no_overlap = val_df[~val_df['Image_Path'].apply(extract_pattern).isin(overlap_train_val)]\n",
    "\n",
    "    return train_df_no_overlap, val_df_no_overlap\n",
    "\n",
    "def delete_images(image_paths):\n",
    "    for path in image_paths:\n",
    "        try:\n",
    "            os.remove(path)\n",
    "            print(f\"Deleted: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccc391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: PLANKTON_LARVAE\n",
      "Total: 372 | Train: 223 | Val: 74 | Test: 75\n",
      "---\n",
      "Class: FLOCK\n",
      "Total: 4555 | Train: 2733 | Val: 911 | Test: 911\n",
      "---\n",
      "Class: RADIOLARIAN\n",
      "Total: 1204 | Train: 722 | Val: 240 | Test: 242\n",
      "---\n",
      "Class: APPENDICULARIAN\n",
      "Total: 3131 | Train: 1878 | Val: 626 | Test: 627\n",
      "---\n",
      "Class: NAUPLII\n",
      "Total: 1650 | Train: 990 | Val: 330 | Test: 330\n",
      "---\n",
      "Class: DINOFLAGELLATES_CERATIUM\n",
      "Total: 190 | Train: 114 | Val: 38 | Test: 38\n",
      "---\n",
      "Class: FILAMENTOUS_ALGAL_COLONY\n",
      "Total: 3562 | Train: 2137 | Val: 712 | Test: 713\n",
      "---\n",
      "Class: CHAETOCEROS_SUBTILIS\n",
      "Total: 596 | Train: 357 | Val: 119 | Test: 120\n",
      "---\n",
      "Class: PHYTOPLANKTON_HELICAL\n",
      "Total: 629 | Train: 377 | Val: 125 | Test: 127\n",
      "---\n",
      "Class: DIATOM\n",
      "Total: 587 | Train: 352 | Val: 117 | Test: 118\n",
      "---\n",
      "Class: COPEPODS\n",
      "Total: 2812 | Train: 1687 | Val: 562 | Test: 563\n",
      "---\n",
      "Class: DINOFLAGELLATES_NOCTILUCA\n",
      "Total: 1023 | Train: 613 | Val: 204 | Test: 206\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# ### 6:2:2 split\n",
    "\n",
    "# # Provide the input and output folder paths\n",
    "# input_folder_path = \"/uoa/home/s04bs3/data/full/ALL/\"\n",
    "# output_folder_path = \"/uoa/home/s04bs3/data/full/dasa/\"\n",
    "\n",
    "# counts = split_data(input_folder_path, output_folder_path)\n",
    "\n",
    "# # Display counts for each class\n",
    "# for class_name, count_info in counts.items():\n",
    "#     print(f\"Class: {class_name}\")\n",
    "#     print(f\"Total: {count_info['total']} | Train: {count_info['train']} | Val: {count_info['val']} | Test: {count_info['test']}\")\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02a5122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows created: 12183\n",
      "\n",
      "Duplicates in train based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n",
      "\n",
      "Total rows created: 4058\n",
      "\n",
      "Duplicates in val based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n",
      "\n",
      "Total rows created: 4070\n",
      "\n",
      "Duplicates in test based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# ### create csv -- train.csv, val.csv, test.csv & check for duplicates\n",
    "\n",
    "# for n in ['train', 'val', 'test']:\n",
    "#     input_folder_path = f\"/uoa/home/s04bs3/data/full/dasa/{n}/\"\n",
    "#     output_csv_path = f\"/uoa/home/s04bs3/data/full/dasa/{n}.csv\"\n",
    "#     total_rows = create_csv(input_folder_path, output_csv_path)\n",
    "#     print(f'\\nTotal rows created: {total_rows}')\n",
    "#     check_duplicates(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd8af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between train and val: {'21-09-2022-10-12-08.hvdfrm064(462,218)-Z114.50', '21-09-2022-10-03-04.hvdfrm281(1929,1236)-Z39.50', '21-09-2022-08-59-32.hvdfrm101(1814,323)-Z65.00', '21-09-2022-10-07-36.hvdfrm270(267,96)-Z43.00', '21-09-2022-10-01-33.hvdfrm589(1027,443)-Z112.00', '21-09-2022-08-58-32.hvdfrm005(1361,1602)-Z107.00', None, '21-09-2022-09-07-36.hvdfrm029(1058,1535)-Z89.00', '21-09-2022-10-12-08.hvdfrm552(2018,12)-Z127.50'}\n",
      "Overlap between train and test: {'21-09-2022-10-02-34.hvdfrm570(2035,678)-Z65.50', '21-09-2022-10-08-06.hvdfrm124(1383,1835)-Z55.00', '21-09-2022-10-12-08.hvdfrm593(255,1889)-Z90.50', '21-09-2022-10-02-03.hvdfrm422(1058,317)-Z70.50', '21-09-2022-10-08-06.hvdfrm357(916,32)-Z122.50', '21-09-2022-10-09-37.hvdfrm167(0,520)-Z129.00', None, '21-09-2022-10-04-34.hvdfrm339(1475,18)-Z185.00', '21-09-2022-09-08-06.hvdfrm407(1241,353)-Z42.50', '21-09-2022-10-02-03.hvdfrm060(2081,80)-Z50.50', '21-09-2022-10-01-03.hvdfrm577(1376,592)-Z104.50'}\n",
      "Overlap between val and test: {None}\n",
      "\n",
      "\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-08-06.hvdfrm124(1383,1835)-Z55.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-03-04.hvdfrm281(1929,1236)-Z39.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-08-06.hvdfrm357(916,32)-Z122.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-10-09-37.hvdfrm167(0,520)-Z129.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-09-07-36.hvdfrm029(1058,1535)-Z89.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-01-03.hvdfrm577(1376,592)-Z104.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-12-08.hvdfrm552(2018,12)-Z127.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-02-34.hvdfrm570(2035,678)-Z65.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-10-12-08.hvdfrm593(255,1889)-Z90.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-12-08.hvdfrm064(462,218)-Z114.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-10-02-03.hvdfrm422(1058,317)-Z70.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-08-59-32.hvdfrm101(1814,323)-Z65.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-10-07-36.hvdfrm270(267,96)-Z43.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-10-01-33.hvdfrm589(1027,443)-Z112.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-08-58-32.hvdfrm005(1361,1602)-Z107.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-04-34.hvdfrm339(1475,18)-Z185.00.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/PLANKTON_LARVAE/21-09-2022-09-08-06.hvdfrm407(1241,353)-Z42.50.png\n",
      "Deleted: /uoa/home/s04bs3/data/full/dasa/train/RADIOLARIAN/21-09-2022-10-02-03.hvdfrm060(2081,80)-Z50.50.png\n"
     ]
    }
   ],
   "source": [
    "# # Example usage:\n",
    "# train_path = '/uoa/home/s04bs3/data/full/dasa/train.csv'\n",
    "# val_path = '/uoa/home/s04bs3/data/full/dasa/val.csv'\n",
    "# test_path = '/uoa/home/s04bs3/data/full/dasa/test.csv'\n",
    "\n",
    "# train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test = check_leakage(train_path, val_path, test_path)\n",
    "# train_df_no_overlap, val_df_no_overlap = remove_leakage(train_df, val_df, overlap_train_val, overlap_train_test)\n",
    "\n",
    "# # Get full paths for overlapping images\n",
    "# full_paths_train = [get_full_path(pattern, train_df) for pattern in overlap_train_val.union(overlap_train_test) if pattern is not None]\n",
    "# full_paths_val = [get_full_path(pattern, val_df) for pattern in overlap_val_test if pattern is not None]\n",
    "\n",
    "\n",
    "# # Delete images\n",
    "# delete_images(full_paths_train)\n",
    "# delete_images(full_paths_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4466372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 213 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/PLANKTON_LARVAE."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=483x218 at 0x153A9C5701F0>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 2732 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/FLOCK."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=173x156 at 0x153A9C546D00>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 712 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/RADIOLARIAN."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=117x106 at 0x153A9C508280>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 1876 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/APPENDICULARIAN."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=101x106 at 0x153A9FDBE880>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 989 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/NAUPLII."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=149x186 at 0x153A9FDB7220>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 113 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/DINOFLAGELLATES_CERATIUM."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=154x118 at 0x153A9FD9D5B0>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 2136 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/FILAMENTOUS_ALGAL_COLONY."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=255x277 at 0x153A9FDB3550>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 357 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/CHAETOCEROS_SUBTILIS."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=LA size=267x315 at 0x153AA05A9EE0>: 100%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 375 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/PHYTOPLANKTON_HELICAL."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=LA size=166x353 at 0x153AA0466F10>: 100%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 351 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/DIATOM."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=LA size=105x218 at 0x153AA04D7CD0>: 100%|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 1687 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/COPEPODS."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=175x120 at 0x153A9C5D68B0>: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 611 image(s) found.\n",
      "Output directory set to /uoa/home/s04bs3/data/full/dasa/train_o/DINOFLAGELLATES_NOCTILUCA."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=LA size=156x216 at 0x153A9C5348E0>: 100%|\n"
     ]
    }
   ],
   "source": [
    "# ### oversample using augmentations to n=3000\n",
    "\n",
    "# main_folder = \"/uoa/home/s04bs3/data/full/dasa/train\"\n",
    "# output_folder = \"/uoa/home/s04bs3/data/full/dasa/train_o/\"\n",
    "\n",
    "# oversample_aug(main_folder, output_folder, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13b2a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows created: 36000\n",
      "\n",
      "\n",
      "Total rows created: 4058\n",
      "\n",
      "\n",
      "Total rows created: 4070\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ### final csv files\n",
    "\n",
    "# for n in ['train_o','val','test']:\n",
    "#     input_folder_path = f\"/uoa/home/s04bs3/data/full/dasa/{n}/\"\n",
    "#     output_csv_path = f\"/uoa/home/s04bs3/data/full/dasa/{n}.csv\"\n",
    "#     total_rows = create_csv(input_folder_path, output_csv_path)\n",
    "#     print(f'Total rows created: {total_rows}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62196693-faef-40a7-b3cb-44ba8899f61c",
   "metadata": {},
   "source": [
    "### Functions to train, evaluate and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7363895-29ad-4ae0-9f3b-ebf8327e295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_data, val_data, epochs=10, batch_size=32):\n",
    "    \n",
    "    target_size=(224,224)\n",
    "\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size=(299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    \n",
    "    # Set up data generators\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "\n",
    "    # Set up data generators\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Build model based on model_name\n",
    "    base_model = None\n",
    "\n",
    "    if model_name == \"MobileNetV2\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV2-0.75\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV2-0.5\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.5)\n",
    "    elif model_name == \"MobileNetV3Small\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Small-0.75\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Small-Min\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"MobileNetV3Large\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Large-0.75\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Large-Min\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"InceptionV3\":\n",
    "        base_model = InceptionV3(input_shape=(299,299, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet101\":\n",
    "        base_model = ResNet101(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet152\":\n",
    "        base_model = ResNet152(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    if base_model:\n",
    "        base_model.trainable = False\n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(12, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Define callbacks (EarlyStopping)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(f\"/uoa/home/s04bs3/data/full/dasa/models/{model_name}.h5\", save_best_only=True)\n",
    "\n",
    "        # Start the timer for training\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        # Stop the timer for training\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate and print the training time\n",
    "        training_time = round(end_time - start_time,2)\n",
    "        print(f\"Training Time: {training_time} seconds\")\n",
    "\n",
    "        return model, history\n",
    "\n",
    "    else:\n",
    "        print(f\"Model {model_name} not recognized.\")\n",
    "        return None, None\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def evaluate_model(model_name, model_path, test_csv_path, target_size=(224, 224), batch_size=32):\n",
    "    # Load the test data\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create an ImageDataGenerator for test data\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size = (299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)  # You may need to adjust this based on your training data preprocessing\n",
    "\n",
    "    # Configure the test generator\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False  # Important: set shuffle to False for reproducibility\n",
    "    )\n",
    "\n",
    "    # Start the timer for testing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    # Stop the timer for testing\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the testing time\n",
    "    testing_time = round(end_time - start_time, 2)\n",
    "    print(f\"Testing Time: {testing_time} seconds\")\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Convert true labels to class labels\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred_classes)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    # Calculate and print classification report\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    save_results(model_name, conf_mat, report, testing_time)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def save_results(model_name, conf_mat, report, testing_time):\n",
    "    # Save all results in a single text file\n",
    "    with open(f\"/uoa/home/s04bs3/data/full/dasa/results/{model_name}_results.txt\", 'w') as file:\n",
    "        file.write(\"Confusion Matrix:\\n\")\n",
    "        file.write(np.array_str(conf_mat))\n",
    "        file.write(\"\\n\\nClassification Report:\\n\")\n",
    "        file.write(report)\n",
    "        file.write(f\"\\nTesting Time: {testing_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d9cdd-7262-42de-85f5-6f0b6508718a",
   "metadata": {},
   "source": [
    "### Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f40a3d-a926-49b3-93ac-c46ba8189f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 14.66 seconds\n",
      "Confusion Matrix:\n",
      "[[496   2  47   0  57   5   0   3   3   3  11   0]\n",
      " [  0 111   2   0   0   0   0   1   0   0   4   1]\n",
      " [ 12   1 438   0   6   1   1  35  39   3  25   1]\n",
      " [  1   6   5  95   2   1   0   2   1   4   1   0]\n",
      " [  1   0   0   0  35   0   0   0   0   1   0   1]\n",
      " [  1   0   0   0   0 205   0   0   0   0   0   0]\n",
      " [  0   0  26   0   2   0 612  62   6   4   0   1]\n",
      " [  7   0  36   2   2   0   1 846   8   3   1   5]\n",
      " [  3   0  18   0   6   0   0  13 281   6   1   1]\n",
      " [  2   0   3   0   8   4   1   6   0 102   1   0]\n",
      " [  1   0   8   0   0   0   0   1   1   1  62   0]\n",
      " [  0   3   3   0   1   0   1   6   1   0  18 208]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.95      0.79      0.86       627\n",
      "     CHAETOCEROS_SUBTILIS       0.90      0.93      0.92       119\n",
      "                 COPEPODS       0.75      0.78      0.76       562\n",
      "                   DIATOM       0.98      0.81      0.88       118\n",
      " DINOFLAGELLATES_CERATIUM       0.29      0.92      0.45        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.95      1.00      0.97       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.86      0.92       713\n",
      "                    FLOCK       0.87      0.93      0.90       911\n",
      "                  NAUPLII       0.83      0.85      0.84       329\n",
      "    PHYTOPLANKTON_HELICAL       0.80      0.80      0.80       127\n",
      "          PLANKTON_LARVAE       0.50      0.84      0.63        74\n",
      "              RADIOLARIAN       0.95      0.86      0.91       241\n",
      "\n",
      "                 accuracy                           0.86      4065\n",
      "                macro avg       0.81      0.86      0.82      4065\n",
      "             weighted avg       0.88      0.86      0.87      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 15.49 seconds\n",
      "Confusion Matrix:\n",
      "[[558   3  10   0  22   0   0   8  12   8   6   0]\n",
      " [  0 116   2   0   0   0   0   0   1   0   0   0]\n",
      " [ 29   2 432   1   1   0   4  20  60   3   9   1]\n",
      " [  5   5   0  98   0   0   0   0   7   3   0   0]\n",
      " [  1   0   0   0  35   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   2   5   0   0   0 671  13  18   3   0   1]\n",
      " [ 16   0  26   6   1   1   7 807  16  31   0   0]\n",
      " [  4   1  19   0   6   0   1   6 288   2   1   1]\n",
      " [  3   0   0   0   4   0   1   4   5 110   0   0]\n",
      " [  6   2   7   0   1   0   0   2   0   1  55   0]\n",
      " [  2  15   5   0  11   0   3   3   2   1   9 190]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.89      0.89      0.89       627\n",
      "     CHAETOCEROS_SUBTILIS       0.79      0.97      0.88       119\n",
      "                 COPEPODS       0.85      0.77      0.81       562\n",
      "                   DIATOM       0.93      0.83      0.88       118\n",
      " DINOFLAGELLATES_CERATIUM       0.43      0.92      0.59        38\n",
      "DINOFLAGELLATES_NOCTILUCA       1.00      1.00      1.00       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.98      0.94      0.96       713\n",
      "                    FLOCK       0.94      0.89      0.91       911\n",
      "                  NAUPLII       0.70      0.88      0.78       329\n",
      "    PHYTOPLANKTON_HELICAL       0.68      0.87      0.76       127\n",
      "          PLANKTON_LARVAE       0.69      0.74      0.71        74\n",
      "              RADIOLARIAN       0.98      0.79      0.88       241\n",
      "\n",
      "                 accuracy                           0.88      4065\n",
      "                macro avg       0.82      0.87      0.84      4065\n",
      "             weighted avg       0.89      0.88      0.88      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 15.33 seconds\n",
      "Confusion Matrix:\n",
      "[[501   0  17   0  71   3   1  22   6   1   5   0]\n",
      " [  0 111   1   0   0   0   3   0   1   0   1   2]\n",
      " [ 17   1 404   0   1   0   3  79  40   2  13   2]\n",
      " [  3   0   3 106   1   0   0   1   1   1   2   0]\n",
      " [  0   0   0   0  37   0   0   0   1   0   0   0]\n",
      " [  1   0   0   0   0 205   0   0   0   0   0   0]\n",
      " [  0   0   1   0   1   0 692  16   1   2   0   0]\n",
      " [  3   0   3   3   1   0   9 883   8   1   0   0]\n",
      " [  3   1  17   0   5   0   3  22 276   2   0   0]\n",
      " [  1   0   1   0   5   1   2   9   1 105   0   2]\n",
      " [  4   0   2   0   1   0   1   7   0   0  58   1]\n",
      " [  0   2   2   0   5   0   2  14   4   0   9 203]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.94      0.80      0.86       627\n",
      "     CHAETOCEROS_SUBTILIS       0.97      0.93      0.95       119\n",
      "                 COPEPODS       0.90      0.72      0.80       562\n",
      "                   DIATOM       0.97      0.90      0.93       118\n",
      " DINOFLAGELLATES_CERATIUM       0.29      0.97      0.45        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.98      1.00      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.97      0.97      0.97       713\n",
      "                    FLOCK       0.84      0.97      0.90       911\n",
      "                  NAUPLII       0.81      0.84      0.83       329\n",
      "    PHYTOPLANKTON_HELICAL       0.92      0.83      0.87       127\n",
      "          PLANKTON_LARVAE       0.66      0.78      0.72        74\n",
      "              RADIOLARIAN       0.97      0.84      0.90       241\n",
      "\n",
      "                 accuracy                           0.88      4065\n",
      "                macro avg       0.85      0.88      0.85      4065\n",
      "             weighted avg       0.90      0.88      0.88      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 14.63 seconds\n",
      "Confusion Matrix:\n",
      "[[583   0  11   5   6   0   0   5   5   2  10   0]\n",
      " [  0 115   0   0   0   0   0   0   0   0   3   1]\n",
      " [  9   0 482   0   1   0   0  15  34   0  21   0]\n",
      " [  2   0   0 116   0   0   0   0   0   0   0   0]\n",
      " [  2   0   1   0  35   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   2   2   0   0 687  18   2   2   0   0]\n",
      " [  3   0   7  20   0   0   1 876   3   0   1   0]\n",
      " [  1   0  34   0   0   0   0  19 274   0   1   0]\n",
      " [  2   0   0   0   2   1   2   3   0 117   0   0]\n",
      " [  0   1   6   0   0   0   0   0   0   0  67   0]\n",
      " [  0   2   2   1   1   0   2  11   3   1  15 203]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.97      0.93      0.95       627\n",
      "     CHAETOCEROS_SUBTILIS       0.97      0.97      0.97       119\n",
      "                 COPEPODS       0.88      0.86      0.87       562\n",
      "                   DIATOM       0.81      0.98      0.89       118\n",
      " DINOFLAGELLATES_CERATIUM       0.78      0.92      0.84        38\n",
      "DINOFLAGELLATES_NOCTILUCA       1.00      1.00      1.00       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.96      0.98       713\n",
      "                    FLOCK       0.93      0.96      0.94       911\n",
      "                  NAUPLII       0.85      0.83      0.84       329\n",
      "    PHYTOPLANKTON_HELICAL       0.96      0.92      0.94       127\n",
      "          PLANKTON_LARVAE       0.57      0.91      0.70        74\n",
      "              RADIOLARIAN       1.00      0.84      0.91       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.89      0.92      0.90      4065\n",
      "             weighted avg       0.93      0.93      0.93      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 14.53 seconds\n",
      "Confusion Matrix:\n",
      "[[549   1  18   2  24   0   1  17   3   9   1   2]\n",
      " [  0 116   0   1   0   0   0   0   0   0   1   1]\n",
      " [  7   0 476   4   3   2   5  23  34   3   3   2]\n",
      " [  0   0   1 111   0   0   0   4   1   1   0   0]\n",
      " [  1   0   0   0  36   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0 698  11   0   3   0   0]\n",
      " [  1   0   5   8   0   0   8 884   5   0   0   0]\n",
      " [  0   0  32   2   0   0   1  22 265   4   1   2]\n",
      " [  0   0   1   0   2   3   3   4   0 114   0   0]\n",
      " [  2   0   5   0   1   0   0   2   1   1  62   0]\n",
      " [  0   1   1   1   0   0   1   5   1   1   9 221]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.98      0.88      0.93       627\n",
      "     CHAETOCEROS_SUBTILIS       0.98      0.97      0.98       119\n",
      "                 COPEPODS       0.88      0.85      0.86       562\n",
      "                   DIATOM       0.86      0.94      0.90       118\n",
      " DINOFLAGELLATES_CERATIUM       0.55      0.95      0.69        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.98      1.00      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.97      0.98      0.98       713\n",
      "                    FLOCK       0.91      0.97      0.94       911\n",
      "                  NAUPLII       0.85      0.81      0.83       329\n",
      "    PHYTOPLANKTON_HELICAL       0.83      0.90      0.86       127\n",
      "          PLANKTON_LARVAE       0.81      0.84      0.82        74\n",
      "              RADIOLARIAN       0.97      0.92      0.94       241\n",
      "\n",
      "                 accuracy                           0.92      4065\n",
      "                macro avg       0.88      0.92      0.89      4065\n",
      "             weighted avg       0.92      0.92      0.92      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 13.93 seconds\n",
      "Confusion Matrix:\n",
      "[[532   0  16   6  17   9   0  13   3  13  10   8]\n",
      " [  0 114   1   1   0   0   0   0   0   0   0   3]\n",
      " [  5   3 450   0   4   4   2  32  32   2  15  13]\n",
      " [  1   0   0 117   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0  37   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   0   1   1   0 674  30   0   3   0   4]\n",
      " [  4   0   5   9   0   0   0 879   4   1   0   9]\n",
      " [  0   0  19   0   3   0   0  27 275   2   0   3]\n",
      " [  2   0   1   1   1   1   3   4   1 111   0   2]\n",
      " [  1   2   7   0   0   0   0   0   0   0  60   4]\n",
      " [  0   0   4   0   1   0   1   5   1   0   9 220]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.97      0.85      0.91       627\n",
      "     CHAETOCEROS_SUBTILIS       0.96      0.96      0.96       119\n",
      "                 COPEPODS       0.89      0.80      0.85       562\n",
      "                   DIATOM       0.87      0.99      0.92       118\n",
      " DINOFLAGELLATES_CERATIUM       0.58      0.97      0.73        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.94      1.00      0.97       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.95      0.97       713\n",
      "                    FLOCK       0.89      0.96      0.92       911\n",
      "                  NAUPLII       0.87      0.84      0.85       329\n",
      "    PHYTOPLANKTON_HELICAL       0.84      0.87      0.86       127\n",
      "          PLANKTON_LARVAE       0.64      0.81      0.71        74\n",
      "              RADIOLARIAN       0.83      0.91      0.87       241\n",
      "\n",
      "                 accuracy                           0.90      4065\n",
      "                macro avg       0.86      0.91      0.88      4065\n",
      "             weighted avg       0.91      0.90      0.90      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 15.21 seconds\n",
      "Confusion Matrix:\n",
      "[[591   2  18   1   4   1   2   1   3   2   1   1]\n",
      " [  0 119   0   0   0   0   0   0   0   0   0   0]\n",
      " [  5   2 508   0   1   0   0  16  25   0   5   0]\n",
      " [  1   0   2 113   0   0   0   2   0   0   0   0]\n",
      " [  1   0   0   0  36   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   5   0   0   0 678  28   0   2   0   0]\n",
      " [  6   0   7   3   1   0   1 891   2   0   0   0]\n",
      " [  0   0  36   0   0   0   0   9 284   0   0   0]\n",
      " [  3   0   2   1   0   3   2   1   0 115   0   0]\n",
      " [  2   0  10   0   0   0   0   1   1   1  59   0]\n",
      " [  0   0   5   0   0   0   1   4   6   0   9 216]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.97      0.94      0.96       627\n",
      "     CHAETOCEROS_SUBTILIS       0.97      1.00      0.98       119\n",
      "                 COPEPODS       0.86      0.90      0.88       562\n",
      "                   DIATOM       0.96      0.96      0.96       118\n",
      " DINOFLAGELLATES_CERATIUM       0.86      0.95      0.90        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.98      1.00      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.95      0.97       713\n",
      "                    FLOCK       0.93      0.98      0.96       911\n",
      "                  NAUPLII       0.88      0.86      0.87       329\n",
      "    PHYTOPLANKTON_HELICAL       0.96      0.91      0.93       127\n",
      "          PLANKTON_LARVAE       0.80      0.80      0.80        74\n",
      "              RADIOLARIAN       1.00      0.90      0.94       241\n",
      "\n",
      "                 accuracy                           0.94      4065\n",
      "                macro avg       0.93      0.93      0.93      4065\n",
      "             weighted avg       0.94      0.94      0.94      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 14.56 seconds\n",
      "Confusion Matrix:\n",
      "[[578   3  13   0   6   0   2   8   0   5  10   2]\n",
      " [  0 119   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 12   1 479   0   1   0   4  28  18   3  13   3]\n",
      " [  1   0   0 117   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0  33   0   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0 693  15   0   2   0   2]\n",
      " [  5   0   4   1   0   0   1 898   1   0   1   0]\n",
      " [  6   0  27   0   4   0   1  24 264   3   0   0]\n",
      " [  5   0   0   1   1   2   2   4   0 110   1   1]\n",
      " [  3   0   3   0   0   0   0   0   1   1  66   0]\n",
      " [  0   0   1   0   1   0   2   6   1   0  10 220]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.94      0.92      0.93       627\n",
      "     CHAETOCEROS_SUBTILIS       0.97      1.00      0.98       119\n",
      "                 COPEPODS       0.91      0.85      0.88       562\n",
      "                   DIATOM       0.98      0.99      0.99       118\n",
      " DINOFLAGELLATES_CERATIUM       0.72      0.87      0.79        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.99      1.00      1.00       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.98      0.97      0.98       713\n",
      "                    FLOCK       0.91      0.99      0.95       911\n",
      "                  NAUPLII       0.93      0.80      0.86       329\n",
      "    PHYTOPLANKTON_HELICAL       0.87      0.87      0.87       127\n",
      "          PLANKTON_LARVAE       0.65      0.89      0.75        74\n",
      "              RADIOLARIAN       0.96      0.91      0.94       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.90      0.92      0.91      4065\n",
      "             weighted avg       0.93      0.93      0.93      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 14.81 seconds\n",
      "Confusion Matrix:\n",
      "[[575   0  10   0  22   0   1   6   3   7   1   2]\n",
      " [  0 116   1   0   0   0   0   0   1   0   0   1]\n",
      " [  7   0 480   0   5   1   2  19  35   6   6   1]\n",
      " [  1   1   1 112   1   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0  37   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  0   0   3   0   0   0 671  21   8   9   0   1]\n",
      " [  5   0   8   3   1   0   3 890   1   0   0   0]\n",
      " [  1   0  14   0   0   0   0   8 306   0   0   0]\n",
      " [  3   0   0   0   3   0   1   1   1 118   0   0]\n",
      " [  2   0   8   0   0   0   0   1   1   2  59   1]\n",
      " [  0   0   3   0   1   0   2   5   2   0   9 219]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.97      0.92      0.94       627\n",
      "     CHAETOCEROS_SUBTILIS       0.99      0.97      0.98       119\n",
      "                 COPEPODS       0.91      0.85      0.88       562\n",
      "                   DIATOM       0.97      0.95      0.96       118\n",
      " DINOFLAGELLATES_CERATIUM       0.53      0.97      0.69        38\n",
      "DINOFLAGELLATES_NOCTILUCA       1.00      1.00      1.00       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.94      0.96       713\n",
      "                    FLOCK       0.93      0.98      0.95       911\n",
      "                  NAUPLII       0.85      0.93      0.89       329\n",
      "    PHYTOPLANKTON_HELICAL       0.83      0.93      0.88       127\n",
      "          PLANKTON_LARVAE       0.79      0.80      0.79        74\n",
      "              RADIOLARIAN       0.97      0.91      0.94       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.89      0.93      0.91      4065\n",
      "             weighted avg       0.94      0.93      0.93      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 16.6 seconds\n",
      "Confusion Matrix:\n",
      "[[557   0  23   2  10   1   1  16   2   4  10   1]\n",
      " [  0 106   6   0   0   0   4   0   0   0   3   0]\n",
      " [ 13   1 479   0   3   2   8  24  25   1   5   1]\n",
      " [  0   1   3 103   1   0   0   7   0   1   2   0]\n",
      " [  3   0   0   0  32   0   0   1   1   1   0   0]\n",
      " [  0   0   0   0   0 206   0   0   0   0   0   0]\n",
      " [  2   0   3   0   2   0 675  26   3   2   0   0]\n",
      " [  6   0  18   4   0   0  28 851   2   2   0   0]\n",
      " [  7   0  43   1   3   0   9  32 229   1   3   1]\n",
      " [  4   0   2   1   2   2   7   5   1 102   0   1]\n",
      " [  1   0   9   0   0   0   1   2   1   0  60   0]\n",
      " [  0   4   9   0   0   0  15  13   3   0   8 189]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.94      0.89      0.91       627\n",
      "     CHAETOCEROS_SUBTILIS       0.95      0.89      0.92       119\n",
      "                 COPEPODS       0.81      0.85      0.83       562\n",
      "                   DIATOM       0.93      0.87      0.90       118\n",
      " DINOFLAGELLATES_CERATIUM       0.60      0.84      0.70        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.98      1.00      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.90      0.95      0.92       713\n",
      "                    FLOCK       0.87      0.93      0.90       911\n",
      "                  NAUPLII       0.86      0.70      0.77       329\n",
      "    PHYTOPLANKTON_HELICAL       0.89      0.80      0.85       127\n",
      "          PLANKTON_LARVAE       0.66      0.81      0.73        74\n",
      "              RADIOLARIAN       0.98      0.78      0.87       241\n",
      "\n",
      "                 accuracy                           0.88      4065\n",
      "                macro avg       0.86      0.86      0.86      4065\n",
      "             weighted avg       0.89      0.88      0.88      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 20.43 seconds\n",
      "Confusion Matrix:\n",
      "[[591   1  18   1   1   0   0   4   3   7   0   1]\n",
      " [  0 116   1   0   0   0   1   0   0   0   0   1]\n",
      " [ 16   0 516   0   0   0   0   8  17   1   1   3]\n",
      " [  1   1   1 106   0   0   0   2   0   6   1   0]\n",
      " [  6   0   1   0  30   0   0   0   0   0   0   1]\n",
      " [  2   0   0   0   0 204   0   0   0   0   0   0]\n",
      " [  1   0  12   0   0   0 678  21   0   1   0   0]\n",
      " [  8   0  17   1   0   0   1 880   1   2   1   0]\n",
      " [  9   0  51   0   3   0   2  23 237   2   0   2]\n",
      " [  7   0   3   1   1   1   1   1   0 110   1   1]\n",
      " [  4   0  11   0   0   0   0   1   1   1  53   3]\n",
      " [  0   0   6   0   0   0   0   2   0   0   8 225]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.92      0.94      0.93       627\n",
      "     CHAETOCEROS_SUBTILIS       0.98      0.97      0.98       119\n",
      "                 COPEPODS       0.81      0.92      0.86       562\n",
      "                   DIATOM       0.97      0.90      0.93       118\n",
      " DINOFLAGELLATES_CERATIUM       0.86      0.79      0.82        38\n",
      "DINOFLAGELLATES_NOCTILUCA       1.00      0.99      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.99      0.95      0.97       713\n",
      "                    FLOCK       0.93      0.97      0.95       911\n",
      "                  NAUPLII       0.92      0.72      0.81       329\n",
      "    PHYTOPLANKTON_HELICAL       0.85      0.87      0.86       127\n",
      "          PLANKTON_LARVAE       0.82      0.72      0.76        74\n",
      "              RADIOLARIAN       0.95      0.93      0.94       241\n",
      "\n",
      "                 accuracy                           0.92      4065\n",
      "                macro avg       0.92      0.89      0.90      4065\n",
      "             weighted avg       0.92      0.92      0.92      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 15.44 seconds\n",
      "Confusion Matrix:\n",
      "[[589   0  12   1   1   1   1   6   2   3   9   2]\n",
      " [  0 115   0   1   0   0   0   0   0   0   0   3]\n",
      " [ 11   0 483   0   1   0   2  23  30   0  10   2]\n",
      " [  7   3   1  99   1   0   1   4   1   0   1   0]\n",
      " [  2   0   0   0  35   0   0   0   0   0   0   1]\n",
      " [  4   0   0   0   0 202   0   0   0   0   0   0]\n",
      " [  0   0   2   0   0   0 696  11   2   2   0   0]\n",
      " [  4   0   3   0   1   0   8 890   0   0   1   4]\n",
      " [  3   0  22   0   3   0   1  13 284   1   0   2]\n",
      " [  5   0   0   0   2   0   2   3   0 115   0   0]\n",
      " [  3   0   1   0   0   0   0   2   1   0  67   0]\n",
      " [  0   0   3   0   0   0   2   1   0   0  11 224]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.94      0.94      0.94       627\n",
      "     CHAETOCEROS_SUBTILIS       0.97      0.97      0.97       119\n",
      "                 COPEPODS       0.92      0.86      0.89       562\n",
      "                   DIATOM       0.98      0.84      0.90       118\n",
      " DINOFLAGELLATES_CERATIUM       0.80      0.92      0.85        38\n",
      "DINOFLAGELLATES_NOCTILUCA       1.00      0.98      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.98      0.98      0.98       713\n",
      "                    FLOCK       0.93      0.98      0.95       911\n",
      "                  NAUPLII       0.89      0.86      0.88       329\n",
      "    PHYTOPLANKTON_HELICAL       0.95      0.91      0.93       127\n",
      "          PLANKTON_LARVAE       0.68      0.91      0.77        74\n",
      "              RADIOLARIAN       0.94      0.93      0.94       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.91      0.92      0.92      4065\n",
      "             weighted avg       0.94      0.93      0.93      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 16.5 seconds\n",
      "Confusion Matrix:\n",
      "[[591   0  10   3   6   1   2   4   1   4   5   0]\n",
      " [  0 113   0   3   1   0   0   0   0   0   2   0]\n",
      " [ 12   0 478   0   0   0   3  22  37   0  10   0]\n",
      " [  1   0   0 114   0   0   0   1   0   1   1   0]\n",
      " [  2   0   0   0  33   0   1   0   2   0   0   0]\n",
      " [  0   0   0   0   0 205   0   1   0   0   0   0]\n",
      " [  0   0   2   0   0   0 706   4   0   1   0   0]\n",
      " [  3   0   5   8   0   0   9 880   4   0   2   0]\n",
      " [  4   0  29   0   1   0   5  19 268   2   1   0]\n",
      " [  1   0   1   2   2   6   1   1   0 113   0   0]\n",
      " [  1   0   1   1   0   0   2   0   0   0  69   0]\n",
      " [  0   2   1   0   0   0   6   4   3   0  11 214]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.96      0.94      0.95       627\n",
      "     CHAETOCEROS_SUBTILIS       0.98      0.95      0.97       119\n",
      "                 COPEPODS       0.91      0.85      0.88       562\n",
      "                   DIATOM       0.87      0.97      0.92       118\n",
      " DINOFLAGELLATES_CERATIUM       0.77      0.87      0.81        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.97      1.00      0.98       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.96      0.99      0.98       713\n",
      "                    FLOCK       0.94      0.97      0.95       911\n",
      "                  NAUPLII       0.85      0.81      0.83       329\n",
      "    PHYTOPLANKTON_HELICAL       0.93      0.89      0.91       127\n",
      "          PLANKTON_LARVAE       0.68      0.93      0.79        74\n",
      "              RADIOLARIAN       1.00      0.89      0.94       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.90      0.92      0.91      4065\n",
      "             weighted avg       0.93      0.93      0.93      4065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/software/uoa/python-pkgs/3.9/pypi/lib/python3.9/site-packages/keras_preprocessing/image/dataframe_iterator.py:279: UserWarning: Found 5 invalid image filename(s) in x_col=\"Image_Path\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4065 validated image filenames belonging to 12 classes.\n",
      "Testing Time: 18.35 seconds\n",
      "Confusion Matrix:\n",
      "[[599   0   3   0  10   1   0   3   1   3   6   1]\n",
      " [  0 113   0   2   0   0   0   1   0   0   2   1]\n",
      " [ 29   0 450   0   2   0   0  15  46   0  17   3]\n",
      " [  2   0   1 108   2   0   0   1   0   0   4   0]\n",
      " [  0   0   0   0  38   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0 205   0   0   0   0   0   0]\n",
      " [  0   0   2   0   1   0 697   5   3   5   0   0]\n",
      " [ 10   0   4   0   1   0   6 882   3   1   4   0]\n",
      " [  5   0  11   1   7   0   4  11 289   0   1   0]\n",
      " [  1   0   0   2   3   2   0   6   1 111   1   0]\n",
      " [  3   0   1   0   0   0   0   1   1   0  65   3]\n",
      " [  0   0   2   0   0   0   2   1   2   0  11 223]]\n",
      "\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "          APPENDICULARIAN       0.92      0.96      0.94       627\n",
      "     CHAETOCEROS_SUBTILIS       1.00      0.95      0.97       119\n",
      "                 COPEPODS       0.95      0.80      0.87       562\n",
      "                   DIATOM       0.96      0.92      0.94       118\n",
      " DINOFLAGELLATES_CERATIUM       0.59      1.00      0.75        38\n",
      "DINOFLAGELLATES_NOCTILUCA       0.99      1.00      0.99       206\n",
      " FILAMENTOUS_ALGAL_COLONY       0.98      0.98      0.98       713\n",
      "                    FLOCK       0.95      0.97      0.96       911\n",
      "                  NAUPLII       0.84      0.88      0.86       329\n",
      "    PHYTOPLANKTON_HELICAL       0.93      0.87      0.90       127\n",
      "          PLANKTON_LARVAE       0.59      0.88      0.70        74\n",
      "              RADIOLARIAN       0.97      0.93      0.94       241\n",
      "\n",
      "                 accuracy                           0.93      4065\n",
      "                macro avg       0.89      0.93      0.90      4065\n",
      "             weighted avg       0.94      0.93      0.93      4065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = [\"MobileNetV2\",\"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "train_data = pd.read_csv(\"/uoa/home/s04bs3/data/full/dasa/train_o.csv\")\n",
    "val_data = pd.read_csv(\"/uoa/home/s04bs3/data/full/dasa/val.csv\")\n",
    "test_csv_path = '/uoa/home/s04bs3/data/full/dasa/test.csv'\n",
    "\n",
    "for n in range(len(model_name)):\n",
    "    # Train the model\n",
    "    model, history = train_model(model_name[n], train_data, val_data, epochs=30, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model_path = f'/uoa/home/s04bs3/data/full/dasa/models/{model_name[n]}.h5'    \n",
    "    evaluate_model(model_name[n], model_path, test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb2fde0-0612-473d-9c0b-08e473e6b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2 - Model Size: 10.85 MB | Number of Parameters: 2.43 million\n",
      "MobileNetV2-0.75 - Model Size: 7.51 MB | Number of Parameters: 1.55 million\n",
      "MobileNetV2-0.5 - Model Size: 4.93 MB | Number of Parameters: 0.87 million\n",
      "MobileNetV3Small - Model Size: 4.78 MB | Number of Parameters: 1.02 million\n",
      "MobileNetV3Small-0.75 - Model Size: 3.22 MB | Number of Parameters: 0.64 million\n",
      "MobileNetV3Small-Min - Model Size: 2.80 MB | Number of Parameters: 0.52 million\n",
      "MobileNetV3Large - Model Size: 13.25 MB | Number of Parameters: 3.12 million\n",
      "MobileNetV3Large-0.75 - Model Size: 8.37 MB | Number of Parameters: 1.91 million\n",
      "MobileNetV3Large-Min - Model Size: 7.24 MB | Number of Parameters: 1.57 million\n",
      "VGG16 - Model Size: 57.01 MB | Number of Parameters: 14.78 million\n",
      "InceptionV3 - Model Size: 86.73 MB | Number of Parameters: 22.07 million\n",
      "ResNet50 - Model Size: 93.37 MB | Number of Parameters: 23.85 million\n",
      "ResNet101 - Model Size: 166.41 MB | Number of Parameters: 42.92 million\n",
      "ResNet152 - Model Size: 226.66 MB | Number of Parameters: 58.64 million\n"
     ]
    }
   ],
   "source": [
    "# Replace this with the path to your saved models directory\n",
    "models_directory = '/uoa/home/s04bs3/data/full/dasa/models/'\n",
    "\n",
    "# List of model names\n",
    "model_name = [\"MobileNetV2\", \"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "for model in model_name:\n",
    "    # Load the model\n",
    "    model_path = os.path.join(models_directory, f'{model}.h5')\n",
    "    loaded_model = load_model(model_path)\n",
    "\n",
    "    # Get the size of the model file\n",
    "    model_size_bytes = os.path.getsize(model_path)\n",
    "\n",
    "    # Convert size to MB\n",
    "    model_size_MB = model_size_bytes / (1024 * 1024)\n",
    "\n",
    "    # Get the number of parameters (in millions)\n",
    "    num_params = loaded_model.count_params() / 1e6\n",
    "\n",
    "    print(f\"{model} - Model Size: {model_size_MB:.2f} MB | Number of Parameters: {num_params:.2f} million\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16235521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
