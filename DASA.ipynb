{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c998ff-2a85-4743-82be-b7dac8b7389e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eba661-86ab-48eb-bc34-e727a2ad759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install Augmentor scikit-learn gputil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe228c62-a957-48b9-a5fc-0adf51610f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import GPUtil\n",
    "import random\n",
    "import shutil\n",
    "import Augmentor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small, MobileNetV3Large, VGG16, InceptionV3, ResNet50, ResNet101, ResNet152\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_input_mobilenet_v2\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input as preprocess_input_mobilenet_v3\n",
    "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
    "from keras.applications.inception_v3 import preprocess_input as preprocess_input_inceptionv3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as preprocess_input_resnet101\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as preprocess_input_resnet152"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99778eb-cd7b-492f-a1b9-da2f7416bae1",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0859f305-61b7-43c9-add0-b0e0ed207d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.8.0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb9f9d3-7c25-4b3d-88fa-95e82910fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 2080 Ti, GPU Load: 0.0%\n",
      "GPU 1: NVIDIA GeForce RTX 2080 Ti, GPU Load: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Get GPU information\n",
    "gpus = GPUtil.getGPUs()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU {gpu.id}: {gpu.name}, GPU Load: {gpu.load * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d823e6",
   "metadata": {},
   "source": [
    "### 8:1:1 split of each folder -> oversampling using augmentations -> creating csv files [all done only once]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8b279-5b7d-497d-b6b7-47be18373b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Done only once. Hence, commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36215fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "# import random\n",
    "\n",
    "# def split_data(input_folder, output_folder):\n",
    "#     # Create train, val, and test folders\n",
    "#     train_folder = os.path.join(output_folder, 'train')\n",
    "#     val_folder = os.path.join(output_folder, 'val')\n",
    "#     test_folder = os.path.join(output_folder, 'test')\n",
    "\n",
    "#     os.makedirs(train_folder, exist_ok=True)\n",
    "#     os.makedirs(val_folder, exist_ok=True)\n",
    "#     os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "#     # Dictionary to store counts for each class\n",
    "#     class_counts = {}\n",
    "\n",
    "#     # Iterate through each class folder in the input folder\n",
    "#     for class_folder in os.listdir(input_folder):\n",
    "#         class_path = os.path.join(input_folder, class_folder)\n",
    "\n",
    "#         # Skip if it's not a directory\n",
    "#         if not os.path.isdir(class_path):\n",
    "#             continue\n",
    "\n",
    "#         # Create subfolders in train, val, and test\n",
    "#         train_class_folder = os.path.join(train_folder, class_folder)\n",
    "#         val_class_folder = os.path.join(val_folder, class_folder)\n",
    "#         test_class_folder = os.path.join(test_folder, class_folder)\n",
    "\n",
    "#         os.makedirs(train_class_folder, exist_ok=True)\n",
    "#         os.makedirs(val_class_folder, exist_ok=True)\n",
    "#         os.makedirs(test_class_folder, exist_ok=True)\n",
    "\n",
    "#         # Get the list of images in the class folder\n",
    "#         images = os.listdir(class_path)\n",
    "#         random.shuffle(images)\n",
    "\n",
    "#         # Calculate the number of images for each split\n",
    "#         total_images = len(images)\n",
    "#         train_split = int(0.6 * total_images)\n",
    "#         val_split = int(0.2 * total_images)\n",
    "\n",
    "#         # Copy images to train, val, and test folders\n",
    "#         for i, image in enumerate(images):\n",
    "#             src_path = os.path.join(class_path, image)\n",
    "            \n",
    "#             if i < train_split:\n",
    "#                 dst_path = os.path.join(train_class_folder, image)\n",
    "#             elif i < train_split + val_split:\n",
    "#                 dst_path = os.path.join(val_class_folder, image)\n",
    "#             else:\n",
    "#                 dst_path = os.path.join(test_class_folder, image)\n",
    "\n",
    "#             shutil.copy(src_path, dst_path)\n",
    "\n",
    "#         # Update class counts dictionary\n",
    "#         class_counts[class_folder] = {\n",
    "#             'total': total_images,\n",
    "#             'train': train_split,\n",
    "#             'val': val_split,\n",
    "#             'test': total_images - train_split - val_split\n",
    "#         }\n",
    "\n",
    "#     return class_counts\n",
    "\n",
    "\n",
    "# # Provide the input and output folder paths\n",
    "# input_folder_path = \"/uoa/home/s04bs3/data/full/ALL/\"\n",
    "# output_folder_path = \"/uoa/home/s04bs3/data/full/dasa/\"\n",
    "\n",
    "# counts = split_data(input_folder_path, output_folder_path)\n",
    "\n",
    "# # Display counts for each class\n",
    "# for class_name, count_info in counts.items():\n",
    "#     print(f\"Class: {class_name}\")\n",
    "#     print(f\"Total: {count_info['total']} | Train: {count_info['train']} | Val: {count_info['val']} | Test: {count_info['test']}\")\n",
    "#     print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_folder = \"/uoa/home/s04bs3/data/full/dasa/train\"\n",
    "# output_folder = \"/uoa/home/s04bs3/data/full/dasa/train_o/\"\n",
    "\n",
    "# # Iterate over subfolders\n",
    "# for subfolder in os.listdir(main_folder):\n",
    "#     subfolder_path = os.path.join(main_folder, subfolder)\n",
    "\n",
    "#     # Check if it's a directory\n",
    "#     if os.path.isdir(subfolder_path):\n",
    "#         # Check if the directory contains images\n",
    "#         if any(f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tif')) for f in os.listdir(subfolder_path)):\n",
    "#             # Create an Augmentor pipeline for each subfolder\n",
    "#             pipeline = Augmentor.Pipeline(subfolder_path, output_directory=os.path.join(output_folder, subfolder))\n",
    "#             # Add your augmentations here\n",
    "#             pipeline.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\n",
    "#             pipeline.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "#             pipeline.flip_left_right(probability=0.5)\n",
    "#             pipeline.flip_top_bottom(probability=0.5)\n",
    "\n",
    "#             # Execute the augmentation process\n",
    "#             pipeline.sample(3000)  # Adjust the number of samples as needed\n",
    "#         else:\n",
    "#             print(f\"No images found in {subfolder_path}. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7362c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows created: 12183\n"
     ]
    }
   ],
   "source": [
    "# def create_csv(input_folder, output_csv):\n",
    "#     # Open CSV file in write mode\n",
    "#     with open(output_csv, 'w', newline='') as csv_file:\n",
    "#         # Create CSV writer\n",
    "#         csv_writer = csv.writer(csv_file)\n",
    "        \n",
    "#         # Write header\n",
    "#         csv_writer.writerow(['Image_Path', 'Label'])\n",
    "\n",
    "#         # Initialize count\n",
    "#         total_rows = 0\n",
    "\n",
    "#         # Iterate through each class folder in the input folder\n",
    "#         for label in os.listdir(input_folder):\n",
    "#             class_folder = os.path.join(input_folder, label)\n",
    "\n",
    "#             # Skip if it's not a directory\n",
    "#             if not os.path.isdir(class_folder):\n",
    "#                 continue\n",
    "\n",
    "#             # Iterate through each image in the class folder\n",
    "#             for image in os.listdir(class_folder):\n",
    "#                 # Get the image path\n",
    "#                 image_path = os.path.join(class_folder, image)\n",
    "\n",
    "#                 # Write the row to the CSV file\n",
    "#                 csv_writer.writerow([image_path, label])\n",
    "\n",
    "#                 # Increment the count\n",
    "#                 total_rows += 1\n",
    "\n",
    "#     return total_rows\n",
    "\n",
    "# # Example usage:\n",
    "# input_folder_path = \"/uoa/home/s04bs3/data/full/dasa/train/\"\n",
    "# output_csv_path = \"/uoa/home/s04bs3/data/full/dasa/train.csv\"\n",
    "\n",
    "# total_rows = create_csv(input_folder_path, output_csv_path)\n",
    "# print(f'Total rows created: {total_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32294249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in train based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n",
      "\n",
      "Duplicates in val based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n",
      "\n",
      "Duplicates in test based on Image_Path:\n",
      "Empty DataFrame\n",
      "Columns: [Image_Path, Label]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates(file):\n",
    "    df = pd.read_csv(f'/uoa/home/s04bs3/data/full/dasa/{file}.csv')\n",
    "    duplicates_specific_columnicates_specific_column = df[df.duplicated(subset=['Image_Path'])]\n",
    "    print(f\"\\nDuplicates in {file} based on Image_Path:\")\n",
    "    print(duplicates_specific_column)\n",
    "\n",
    "check_duplicates('train')\n",
    "check_duplicates('val')\n",
    "check_duplicates('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6f63686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between train and val: {'21-09-2022-08-59-32.hvdfrm101(1814,323)-Z65.00', '21-09-2022-10-06-36.hvdfrm215(231,311)-Z109.50', None, '21-09-2022-10-13-08.hvdfrm484(113,1246)-Z111.00', '21-09-2022-09-59-02.hvdfrm289(247,122)-Z142.00', '21-09-2022-09-06-36.hvdfrm078(2213,1451)-Z76.00', '21-09-2022-09-04-35.hvdfrm454(1104,1483)-Z81.00', '21-09-2022-10-09-37.hvdfrm167(0,520)-Z129.00', '21-09-2022-10-12-08.hvdfrm373(1426,303)-Z89.50'}\n",
      "Overlap between train and test: {'21-09-2022-10-03-04.hvdfrm281(1929,1236)-Z39.50', '21-09-2022-10-04-34.hvdfrm339(1475,18)-Z185.00', '21-09-2022-09-09-07.hvdfrm121(344,1343)-Z100.50', '21-09-2022-09-08-06.hvdfrm407(1241,353)-Z42.50', None, '21-09-2022-10-12-08.hvdfrm593(202,1883)-Z92.50', '21-09-2022-10-03-04.hvdfrm589(471,1632)-Z41.50'}\n",
      "Overlap between val and test: {'21-09-2022-10-02-03.hvdfrm422(1058,317)-Z70.50', '21-09-2022-10-00-33.hvdfrm173(2184,752)-Z58.50', '21-09-2022-09-08-06.hvdfrm150(1989,495)-Z86.00', '21-09-2022-09-09-37.hvdfrm117(1438,965)-Z119.50', None, '21-09-2022-10-02-34.hvdfrm570(2035,678)-Z65.50'}\n",
      "\n",
      "\n",
      "Overlap between train (after removal) and val: set()\n",
      "Overlap between train (after removal) and test: set()\n",
      "Overlap between val (after removal) and test: set()\n",
      "\n",
      "\n",
      "Filtered train set without overlaps saved to train_no_overlap.csv\n",
      "Filtered val set without overlaps saved to val_no_overlap.csv\n",
      "\n",
      "\n",
      "Count of overlap between train and val: 9 -> removed from train.csv\n",
      "Count of overlap between train and test: 7 -> removed from train.csv\n",
      "Count of overlap between val and test: 6 -> removed from val.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_pattern(path):\n",
    "    pattern = r'(\\d{2}-\\d{2}-\\d{4}-\\d{2}-\\d{2}-\\d{2}\\.hvdfrm\\d+\\(\\d+,\\d+\\)-Z\\d+\\.\\d+)'\n",
    "    match = re.search(pattern, path)\n",
    "    return match.group() if match else None\n",
    "\n",
    "def get_paths_with_pattern(df):\n",
    "    return set(df['Image_Path'].apply(extract_pattern))\n",
    "\n",
    "def check_leakage(train_path, val_path, test_path):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_paths = get_paths_with_pattern(train_df)\n",
    "    val_paths = get_paths_with_pattern(val_df)\n",
    "    test_paths = get_paths_with_pattern(test_df)\n",
    "\n",
    "    overlap_train_val = train_paths.intersection(val_paths)\n",
    "    overlap_train_test = train_paths.intersection(test_paths)\n",
    "    overlap_val_test = val_paths.intersection(test_paths)\n",
    "\n",
    "    print(\"Overlap between train and val:\", overlap_train_val)\n",
    "    print(\"Overlap between train and test:\", overlap_train_test)\n",
    "    print(\"Overlap between val and test:\", overlap_val_test)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test\n",
    "\n",
    "def remove_leakage(train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test):\n",
    "    # Filter rows from train_df where Image_Path is in overlap_train_val or overlap_train_test\n",
    "    train_df_no_overlap = train_df[~train_df['Image_Path'].apply(extract_pattern).isin(overlap_train_val.union(overlap_train_test))]\n",
    "\n",
    "    # Filter rows from val_df where Image_Path is in overlap_val_test\n",
    "    val_df_no_overlap = val_df[~val_df['Image_Path'].apply(extract_pattern).isin(overlap_val_test)]\n",
    "\n",
    "    return train_df_no_overlap, val_df_no_overlap\n",
    "\n",
    "def check_leakage_after_removal(train_df_no_overlap, val_df_no_overlap, test_path):\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    train_paths_no_overlap = get_paths_with_pattern(train_df_no_overlap)\n",
    "    val_paths_no_overlap = get_paths_with_pattern(val_df_no_overlap)\n",
    "    test_paths = get_paths_with_pattern(test_df)\n",
    "\n",
    "    overlap_train_val_no_overlap = train_paths_no_overlap.intersection(val_paths_no_overlap)\n",
    "    overlap_train_test_no_overlap = train_paths_no_overlap.intersection(test_paths)\n",
    "    overlap_val_test_no_overlap = val_paths_no_overlap.intersection(test_paths)\n",
    "\n",
    "    print(\"Overlap between train (after removal) and val:\", overlap_train_val_no_overlap)\n",
    "    print(\"Overlap between train (after removal) and test:\", overlap_train_test_no_overlap)\n",
    "    print(\"Overlap between val (after removal) and test:\", overlap_val_test_no_overlap)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return overlap_val_test_no_overlap\n",
    "\n",
    "def write_to_new_csv(train_df_no_overlap, val_df_no_overlap):\n",
    "    # Save the updated train_df and val_df without overlaps to new CSV files\n",
    "#     train_df_no_overlap.to_csv('/uoa/home/s04bs3/data/full/dasa/train_no_overlap.csv', index=False)\n",
    "#     val_df_no_overlap.to_csv('/uoa/home/s04bs3/data/full/dasa/val_no_overlap.csv', index=False)\n",
    "    print(f\"Filtered train set without overlaps saved to train_no_overlap.csv\")\n",
    "    print(f\"Filtered val set without overlaps saved to val_no_overlap.csv\")\n",
    "\n",
    "# Example usage:\n",
    "train_path = '/uoa/home/s04bs3/data/full/dasa/train.csv'\n",
    "val_path = '/uoa/home/s04bs3/data/full/dasa/val.csv'\n",
    "test_path = '/uoa/home/s04bs3/data/full/dasa/test.csv'\n",
    "\n",
    "train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test = check_leakage(train_path, val_path, test_path)\n",
    "train_df_no_overlap, val_df_no_overlap = remove_leakage(train_df, val_df, test_df, overlap_train_val, overlap_train_test, overlap_val_test)\n",
    "overlap_val_test_no_overlap = check_leakage_after_removal(train_df_no_overlap, val_df_no_overlap, test_path)\n",
    "\n",
    "# Verify that the overlap has been successfully removed\n",
    "if not overlap_val_test_no_overlap:\n",
    "    write_to_new_csv(train_df_no_overlap, val_df_no_overlap)\n",
    "else:\n",
    "    print(\"Error: Overlap still exists after removal. Please review the process.\")\n",
    "\n",
    "# Counts of overlaps\n",
    "count_overlap_train_val = len(overlap_train_val)\n",
    "count_overlap_train_test = len(overlap_train_test)\n",
    "count_overlap_val_test = len(overlap_val_test)\n",
    "print(f\"\\n\\nCount of overlap between train and val: {count_overlap_train_val} -> removed from train.csv\")\n",
    "print(f\"Count of overlap between train and test: {count_overlap_train_test} -> removed from train.csv\")\n",
    "print(f\"Count of overlap between val and test: {count_overlap_val_test} -> removed from val.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62196693-faef-40a7-b3cb-44ba8899f61c",
   "metadata": {},
   "source": [
    "### Functions to train, evaluate and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7363895-29ad-4ae0-9f3b-ebf8327e295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, train_data, val_data, epochs=10, batch_size=32):\n",
    "    \n",
    "    target_size=(224,224)\n",
    "\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size=(299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    \n",
    "    # Set up data generators\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=prep_fn)\n",
    "\n",
    "    # Set up data generators\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Build model based on model_name\n",
    "    base_model = None\n",
    "\n",
    "    if model_name == \"MobileNetV2\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV2-0.75\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV2-0.5\":\n",
    "        base_model = MobileNetV2(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.5)\n",
    "    elif model_name == \"MobileNetV3Small\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Small-0.75\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Small-Min\":\n",
    "        base_model = MobileNetV3Small(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"MobileNetV3Large\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"MobileNetV3Large-0.75\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", alpha=0.75)\n",
    "    elif model_name == \"MobileNetV3Large-Min\":\n",
    "        base_model = MobileNetV3Large(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\", minimalistic=True)\n",
    "    elif model_name == \"VGG16\":\n",
    "        base_model = VGG16(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"InceptionV3\":\n",
    "        base_model = InceptionV3(input_shape=(299,299, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet50\":\n",
    "        base_model = ResNet50(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet101\":\n",
    "        base_model = ResNet101(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "    elif model_name == \"ResNet152\":\n",
    "        base_model = ResNet152(input_shape=(224,224, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    if base_model:\n",
    "        base_model.trainable = False\n",
    "\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(12, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Define callbacks (EarlyStopping)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "        model_checkpoint = ModelCheckpoint(f\"/uoa/home/s04bs3/data/full/dasa/models/{model_name}.h5\", save_best_only=True)\n",
    "\n",
    "        # Start the timer for training\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            callbacks=[early_stopping, model_checkpoint]\n",
    "        )\n",
    "\n",
    "        # Stop the timer for training\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate and print the training time\n",
    "        training_time = round(end_time - start_time,2)\n",
    "        print(f\"Training Time: {training_time} seconds\")\n",
    "\n",
    "        return model, history\n",
    "\n",
    "    else:\n",
    "        print(f\"Model {model_name} not recognized.\")\n",
    "        return None, None\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def evaluate_model(model_name, model_path, test_csv_path, target_size=(224, 224), batch_size=32):\n",
    "    # Load the test data\n",
    "    test_data = pd.read_csv(test_csv_path)\n",
    "\n",
    "    # Load the saved model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Create an ImageDataGenerator for test data\n",
    "    if model_name.lower() in [\"mobilenetv2\", \"mobilenetv2-0.5\", \"mobilenetv2-0.75\"]:\n",
    "        prep_fn = preprocess_input_mobilenet_v2\n",
    "    elif model_name.lower() == \"vgg16\":\n",
    "        prep_fn = preprocess_input_vgg16\n",
    "    elif model_name.lower() == \"inceptionv3\":\n",
    "        prep_fn = preprocess_input_inceptionv3\n",
    "        target_size = (299,299)\n",
    "    elif model_name.lower() == \"ResNet50\":\n",
    "        prep_fn = preprocess_input_resnet50\n",
    "    elif model_name.lower() == \"ResNet101\":\n",
    "        prep_fn = preprocess_input_resnet101\n",
    "    elif model_name.lower() == \"ResNet152\":\n",
    "        prep_fn = preprocess_input_resnet152\n",
    "    else:\n",
    "        prep_fn = preprocess_input_mobilenet_v3\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=prep_fn)  # You may need to adjust this based on your training data preprocessing\n",
    "\n",
    "    # Configure the test generator\n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_data,\n",
    "        x_col=\"Image_Path\",\n",
    "        y_col=\"Label\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False  # Important: set shuffle to False for reproducibility\n",
    "    )\n",
    "\n",
    "    # Start the timer for testing\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(test_generator)\n",
    "\n",
    "    # Stop the timer for testing\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the testing time\n",
    "    testing_time = round(end_time - start_time, 2)\n",
    "    print(f\"Testing Time: {testing_time} seconds\")\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Convert true labels to class labels\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Calculate and print confusion matrix\n",
    "    conf_mat = confusion_matrix(y_true, y_pred_classes)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_mat)\n",
    "\n",
    "    # Calculate and print classification report\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    report = classification_report(y_true, y_pred_classes, target_names=class_labels)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    save_results(model_name, conf_mat, report, testing_time)\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "def save_results(model_name, conf_mat, report, testing_time):\n",
    "    # Save all results in a single text file\n",
    "    with open(f\"/uoa/home/s04bs3/data/full/dasa/results/{model_name}_results.txt\", 'w') as file:\n",
    "        file.write(\"Confusion Matrix:\\n\")\n",
    "        file.write(np.array_str(conf_mat))\n",
    "        file.write(\"\\n\\nClassification Report:\\n\")\n",
    "        file.write(report)\n",
    "        file.write(f\"\\nTesting Time: {testing_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d9cdd-7262-42de-85f5-6f0b6508718a",
   "metadata": {},
   "source": [
    "### Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f40a3d-a926-49b3-93ac-c46ba8189f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = [\"MobileNetV2-0.5\",\"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "train_data = pd.read_csv(\"/uoa/home/s04bs3/data/full/dasa/train_o.csv\")\n",
    "val_data = pd.read_csv(\"/uoa/home/s04bs3/data/full/dasa/val.csv\")\n",
    "test_csv_path = '/uoa/home/s04bs3/data/full/dasa/test.csv'\n",
    "\n",
    "for n in range(len(model_name)):\n",
    "    # Train the model\n",
    "    model, history = train_model(model_name[n], train_data, val_data, epochs=30, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model_path = f'/uoa/home/s04bs3/data/full/dasa/models/{model_name[n]}.h5'    \n",
    "    evaluate_model(model_name[n], model_path, test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2fde0-0612-473d-9c0b-08e473e6b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the path to your saved models directory\n",
    "models_directory = '/uoa/home/s04bs3/data/full/dasa/models/'\n",
    "\n",
    "# List of model names\n",
    "model_name = [\"MobileNetV2\", \"MobileNetV2-0.75\", \"MobileNetV2-0.5\",\n",
    "              \"MobileNetV3Small\", \"MobileNetV3Small-0.75\", \"MobileNetV3Small-Min\",\n",
    "              \"MobileNetV3Large\", \"MobileNetV3Large-0.75\", \"MobileNetV3Large-Min\",\n",
    "              \"VGG16\",\"InceptionV3\", \"ResNet50\", \"ResNet101\",\"ResNet152\"]\n",
    "\n",
    "for model in model_name:\n",
    "    # Load the model\n",
    "    model_path = os.path.join(models_directory, f'{model}.h5')\n",
    "    loaded_model = load_model(model_path)\n",
    "\n",
    "    # Get the size of the model file\n",
    "    model_size_bytes = os.path.getsize(model_path)\n",
    "\n",
    "    # Convert size to MB\n",
    "    model_size_MB = model_size_bytes / (1024 * 1024)\n",
    "\n",
    "    # Get the number of parameters (in millions)\n",
    "    num_params = loaded_model.count_params() / 1e6\n",
    "\n",
    "    print(f\"{model} - Model Size: {model_size_MB:.2f} MB | Number of Parameters: {num_params:.2f} million\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
